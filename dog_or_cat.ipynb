{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Checkpoint.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPqHUUbyFZZ+OpALby52NIM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data Source : https://www.kaggle.com/tongpython/cat-and-dog\n",
        "\n",
        "Dikarenakan masih kurangnya pemahaman saya, saya mengikuti tutorial dari [site ini]('https://becominghuman.ai/building-an-image-classifier-using-deep-learning-in-python-totally-from-a-beginners-perspective-be8dbaf22dd8')"
      ],
      "metadata": {
        "id": "v1Db8TYg2Kij"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ty-LJ4O1zDM"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download tongpython/cat-and-dog"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile, os\n",
        "local_zip = '/content/cat-and-dog.zip'\n",
        "\n",
        "# Buat dataset folder\n",
        "zip_target = '/content/data'\n",
        "!mkdir /content/data/\n",
        "\n",
        "# Unzip dataset\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall(zip_target)\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "aa09A9792dCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ptQqa4gZ4cWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "5INVtZmE5Ma5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XCXIvHvp8G5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = '/content/data/training_set/training_set'\n",
        "test_data = '/content/data/test_set/test_set'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale          = 1./255, \n",
        "                                   shear_range      = 0.2, \n",
        "                                   zoom_range       = 0.2, \n",
        "                                   horizontal_flip  = True\n",
        "                                   )\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(train_data, \n",
        "                                                 target_size  = (64,64),\n",
        "                                                 batch_size   = 32,\n",
        "                                                 class_mode   = 'binary'\n",
        "                                                 )\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(test_data,\n",
        "                                            target_size=(64,64),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='binary'\n",
        "                                            )"
      ],
      "metadata": {
        "id": "C-90eG6x8jiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit(training_set,\n",
        "              steps_per_epoch  = 249,\n",
        "              epochs           = 25,\n",
        "              validation_data  = test_set,\n",
        "              validation_steps = 62\n",
        "              )"
      ],
      "metadata": {
        "id": "_qL1AYu3-0Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_image = image.load_img('/content/guess1.jpg',\n",
        "#                             target_size=(64,64)\n",
        "#                             )\n",
        "test_image = image.load_img('/content/guess4.jpg',\n",
        "                            target_size=(64,64)\n",
        "                            )\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = classifier.predict(test_image)\n",
        "training_set.class_indices\n",
        "\n",
        "if result[0][0]==1:\n",
        "  prediction = 'Dog'\n",
        "else:\n",
        "  prediction = 'Cat'\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "l7IrTTeU_eNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.save('/content/model.h5')"
      ],
      "metadata": {
        "id": "hCanwD-TbR8-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}